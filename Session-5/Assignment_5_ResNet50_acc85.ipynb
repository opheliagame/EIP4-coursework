{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 5 ResNet50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "outputId": "93d161e7-7dcb-4e49-a357-a873f3b197c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "replace resized/9733.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/              model.png  \u001b[01;34msample_data\u001b[0m/   vgg16-untrained-10epochs.jpg\n",
            "hvc_annotations.csv  \u001b[01;34mresized\u001b[0m/   \u001b[01;34msaved_models\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "from keras.applications import ResNet50\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojp7mZPeegyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "data_augmentation = True\n",
        "pixel_level = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "outputId": "b2533755-6cbe-4618-bef6-a288ab67b3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>imagequality</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>carryingbag</th>\n",
              "      <th>footwear</th>\n",
              "      <th>emotion</th>\n",
              "      <th>bodypose</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>over-weight</td>\n",
              "      <td>None</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Angry/Serious</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Daily/Office/Work Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>Good</td>\n",
              "      <td>35-45</td>\n",
              "      <td>slightly-overweight</td>\n",
              "      <td>None</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender imagequality    age  ...        emotion        bodypose     image_path\n",
              "0    male      Average  35-45  ...        Neutral  Front-Frontish  resized/1.jpg\n",
              "1  female      Average  35-45  ...  Angry/Serious  Front-Frontish  resized/2.jpg\n",
              "2    male         Good  45-55  ...        Neutral  Front-Frontish  resized/3.jpg\n",
              "3    male         Good  45-55  ...        Neutral  Front-Frontish  resized/4.jpg\n",
              "4  female         Good  35-45  ...        Neutral  Front-Frontish  resized/5.jpg\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "outputId": "9e4fb209-53a5-4391-ded5-5148b01a70b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>image_path</th>\n",
              "      <td>resized/1.jpg</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_female</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_male</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Average</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Good</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_15-25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_25-35</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_35-45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_45-55</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_55+</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_over-weight</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_underweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_None</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Normal</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Happy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Sad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Back</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Side</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  0  ...              4\n",
              "image_path                            resized/1.jpg  ...  resized/5.jpg\n",
              "gender_female                                     0  ...              1\n",
              "gender_male                                       1  ...              0\n",
              "imagequality_Average                              1  ...              0\n",
              "imagequality_Bad                                  0  ...              0\n",
              "imagequality_Good                                 0  ...              1\n",
              "age_15-25                                         0  ...              0\n",
              "age_25-35                                         0  ...              0\n",
              "age_35-45                                         1  ...              1\n",
              "age_45-55                                         0  ...              0\n",
              "age_55+                                           0  ...              0\n",
              "weight_normal-healthy                             1  ...              0\n",
              "weight_over-weight                                0  ...              0\n",
              "weight_slightly-overweight                        0  ...              1\n",
              "weight_underweight                                0  ...              0\n",
              "carryingbag_Daily/Office/Work Bag                 0  ...              0\n",
              "carryingbag_Grocery/Home/Plastic Bag              1  ...              0\n",
              "carryingbag_None                                  0  ...              1\n",
              "footwear_CantSee                                  0  ...              1\n",
              "footwear_Fancy                                    0  ...              0\n",
              "footwear_Normal                                   1  ...              0\n",
              "emotion_Angry/Serious                             0  ...              0\n",
              "emotion_Happy                                     0  ...              0\n",
              "emotion_Neutral                                   1  ...              1\n",
              "emotion_Sad                                       0  ...              0\n",
              "bodypose_Back                                     0  ...              0\n",
              "bodypose_Front-Frontish                           1  ...              1\n",
              "bodypose_Side                                     0  ...              0\n",
              "\n",
              "[28 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "outputId": "8e23c6ca-a473-4fdf-d271-becb12ee3c11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11537, 28), (2036, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "outputId": "f5573aa2-29b0-4bff-cb16-8d58ec77eb03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df.head()\n",
        "len(train_df.columns)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=32)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "outputId": "a983aff1-3880-458b-f41c-680a09b66961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "print(images.shape)\n",
        "print(targets.keys())\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 224, 224, 3)\n",
            "dict_keys(['gender_output', 'image_quality_output', 'age_output', 'weight_output', 'bag_output', 'pose_output', 'footwear_output', 'emotion_output'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 5,\n",
              " 'bag': 3,\n",
              " 'emotion': 4,\n",
              " 'footwear': 3,\n",
              " 'gender': 2,\n",
              " 'image_quality': 3,\n",
              " 'pose': 3,\n",
              " 'weight': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G3_2YTReYyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    # lr = 1e-3\n",
        "    # if epoch > 180:\n",
        "    #     lr *= 0.5e-3\n",
        "    # elif epoch > 160:\n",
        "    #     lr *= 1e-3\n",
        "    # elif epoch > 120:\n",
        "    #     lr *= 1e-2\n",
        "    # elif epoch > 80:\n",
        "    #     lr *= 1e-1\n",
        "    lr = round(0.004 * 1/(1 + 0.319 * epoch), 10)\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnXEYMdDdUaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynTC3bYOvN7C",
        "colab_type": "code",
        "outputId": "f8eb3add-3ba4-4403-9ce9-bb731d1cdfed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "backbone = ResNet50(\n",
        "    weights=None, \n",
        "    include_top=False, \n",
        "    input_tensor=Input(shape=(224, 224, 3))\n",
        ")\n",
        "\n",
        "neck = backbone.output\n",
        "neck = Flatten(name=\"flatten\")(neck)\n",
        "neck = Dense(512, activation=\"relu\")(neck)\n",
        "\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    neck = Dropout(0.2)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    neck = Dropout(0.3)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"sigmoid\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_tower(neck))\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    inputs=backbone.input, \n",
        "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "from keras.utils import plot_model"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_393[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_394[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_395[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_129 (Add)                   (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, 56, 56, 256)  0           add_129[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_397 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_397[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_398 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_398[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_130 (Add)                   (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_399 (Activation)     (None, 56, 56, 256)  0           add_130[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_399[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_400 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_400[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_401 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_401[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_131 (Add)                   (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_399[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_402 (Activation)     (None, 56, 56, 256)  0           add_131[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_402[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_403 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_403[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_404 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_404[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_402[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_132 (Add)                   (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_405 (Activation)     (None, 28, 28, 512)  0           add_132[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_405[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_406 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_406[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_407 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_407[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_133 (Add)                   (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_405[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_408 (Activation)     (None, 28, 28, 512)  0           add_133[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_408[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_409 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_409[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_410 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_410[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_134 (Add)                   (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_408[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_411 (Activation)     (None, 28, 28, 512)  0           add_134[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_411[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_412 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_412[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_413 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_413[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_135 (Add)                   (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_411[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_414 (Activation)     (None, 28, 28, 512)  0           add_135[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_414[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_415 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_415[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_416 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_416[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_414[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_136 (Add)                   (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_417 (Activation)     (None, 14, 14, 1024) 0           add_136[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_417[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_418 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_418[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_419 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_419[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_137 (Add)                   (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_417[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_420 (Activation)     (None, 14, 14, 1024) 0           add_137[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_420[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_421 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_421[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_422 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_422[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_138 (Add)                   (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_420[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_423 (Activation)     (None, 14, 14, 1024) 0           add_138[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_423[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_424 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_424[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_425 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_425[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_139 (Add)                   (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_423[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_426 (Activation)     (None, 14, 14, 1024) 0           add_139[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_426[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_427 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_427[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_428 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_428[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_140 (Add)                   (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_426[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_429 (Activation)     (None, 14, 14, 1024) 0           add_140[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_429[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_430 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_430[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_431 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_431[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_141 (Add)                   (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_429[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_432 (Activation)     (None, 14, 14, 1024) 0           add_141[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_432[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_433 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_433[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_434 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_434[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_432[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_142 (Add)                   (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_435 (Activation)     (None, 7, 7, 2048)   0           add_142[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_435[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_436 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_436[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_437 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_437[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_143 (Add)                   (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_435[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_438 (Activation)     (None, 7, 7, 2048)   0           add_143[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_438[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_439 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_439[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_440 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_440[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_144 (Add)                   (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_438[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_441 (Activation)     (None, 7, 7, 2048)   0           add_144[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 100352)       0           activation_441[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_137 (Dense)               (None, 512)          51380736    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 512)          0           dense_137[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_132 (Dropout)           (None, 512)          0           dense_137[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 512)          0           dense_137[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 512)          0           dense_137[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 512)          0           dense_137[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 512)          0           dense_137[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_144 (Dropout)           (None, 512)          0           dense_137[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_142 (Dropout)           (None, 512)          0           dense_137[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_139 (Dense)               (None, 128)          65664       dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_141 (Dense)               (None, 128)          65664       dropout_132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_143 (Dense)               (None, 128)          65664       dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_145 (Dense)               (None, 128)          65664       dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_147 (Dense)               (None, 128)          65664       dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_149 (Dense)               (None, 128)          65664       dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_153 (Dense)               (None, 128)          65664       dropout_144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_151 (Dense)               (None, 128)          65664       dropout_142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Dense)           (None, 2)            258         dense_139[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "image_quality_output (Dense)    (None, 3)            387         dense_141[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "age_output (Dense)              (None, 5)            645         dense_143[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "weight_output (Dense)           (None, 4)            516         dense_145[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bag_output (Dense)              (None, 3)            387         dense_147[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "footwear_output (Dense)         (None, 3)            387         dense_149[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pose_output (Dense)             (None, 3)            387         dense_153[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "emotion_output (Dense)          (None, 4)            516         dense_151[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 75,497,243\n",
            "Trainable params: 75,444,123\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfPG9C2eA1zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# losses = {\n",
        "# \t\"gender_output\": \"binary_crossentropy\",\n",
        "# \t\"image_quality_output\": \"categorical_crossentropy\",\n",
        "# \t\"age_output\": \"categorical_crossentropy\",\n",
        "# \t\"weight_output\": \"categorical_crossentropy\",\n",
        "\n",
        "# }\n",
        "# loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 1.0}\n",
        "sgd = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(\n",
        "    optimizer=sgd,\n",
        "    loss=\"binary_crossentropy\", \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6n3FywXhgjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6266cc89-8433-46df-ba7a-bd3373cfa60f"
      },
      "source": [
        "columns = ['gender_female', 'gender_male', 'imagequality_Average',\n",
        "       'imagequality_Bad', 'imagequality_Good', 'age_15-25', 'age_25-35',\n",
        "       'age_35-45', 'age_45-55', 'age_55+', 'weight_normal-healthy',\n",
        "       'weight_over-weight', 'weight_slightly-overweight',\n",
        "       'weight_underweight', 'carryingbag_Daily/Office/Work Bag',\n",
        "       'carryingbag_Grocery/Home/Plastic Bag', 'carryingbag_None',\n",
        "       'footwear_CantSee', 'footwear_Fancy', 'footwear_Normal',\n",
        "       'emotion_Angry/Serious', 'emotion_Happy', 'emotion_Neutral',\n",
        "       'emotion_Sad', 'bodypose_Back', 'bodypose_Front-Frontish',\n",
        "       'bodypose_Side']\n",
        "print(len(columns))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw2ZRIQ7BW-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "76e0dfa7-e41a-4615-89c8-5cebeec216bf"
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = '%s_model.{epoch:03d}.h5' % 'resnet50'\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "callbacks = [checkpoint, lr_scheduler]\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    history = model.fit_generator(\n",
        "              generator=train_gen,\n",
        "              validation_data=valid_gen,\n",
        "              batch_size=32,\n",
        "              epochs=50,\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=pixel_level),\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None)\n",
        "    \n",
        "    train_gen = datagen.flow_from_dataframe(\n",
        "                          dataframe=train_df, \n",
        "                          batch_size=32,\n",
        "                          x_col='image_path',\n",
        "                          y_col=columns,\n",
        "                          shuffle=True,\n",
        "                          class_mode=\"other\")\n",
        "\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    #datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit_generator(\n",
        "                        generator=train_gen,\n",
        "                        validation_data=valid_gen,\n",
        "                        use_multiprocessing=True,\n",
        "                        epochs=50, \n",
        "                        verbose=1, \n",
        "                        workers=20,\n",
        "                        callbacks=callbacks\n",
        "                        )"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Found 11537 validated image filenames.\n",
            "Epoch 1/50\n",
            "Learning rate:  0.004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-6d6f89962de8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1441\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 8 array(s), but instead got the following list of 1 arrays: [array([[0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n        1, 0, 0, 1, 0],\n       [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n        1, 0, 1, 0, 0],\n   ..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxv41EyNmN4",
        "colab_type": "code",
        "outputId": "5c23bac2-9cdc-4b51-a844-70f27501c73e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=5, \n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.4963 - gender_output_loss: 0.7075 - image_quality_output_loss: 0.6105 - age_output_loss: 0.4912 - weight_output_loss: 0.4578 - bag_output_loss: 0.5815 - footwear_output_loss: 0.6377 - pose_output_loss: 0.5854 - emotion_output_loss: 0.4247 - gender_output_acc: 0.5451 - image_quality_output_acc: 0.6876 - age_output_acc: 0.7909 - weight_output_acc: 0.8088 - bag_output_acc: 0.6914 - footwear_output_acc: 0.6516 - pose_output_acc: 0.7306 - emotion_output_acc: 0.8479Epoch 1/10\n",
            "360/360 [==============================] - 121s 336ms/step - loss: 4.4959 - gender_output_loss: 0.7075 - image_quality_output_loss: 0.6106 - age_output_loss: 0.4911 - weight_output_loss: 0.4576 - bag_output_loss: 0.5813 - footwear_output_loss: 0.6378 - pose_output_loss: 0.5855 - emotion_output_loss: 0.4245 - gender_output_acc: 0.5449 - image_quality_output_acc: 0.6876 - age_output_acc: 0.7909 - weight_output_acc: 0.8089 - bag_output_acc: 0.6916 - footwear_output_acc: 0.6517 - pose_output_acc: 0.7304 - emotion_output_acc: 0.8480 - val_loss: 4.2486 - val_gender_output_loss: 0.6759 - val_image_quality_output_loss: 0.5735 - val_age_output_loss: 0.4684 - val_weight_output_loss: 0.4238 - val_bag_output_loss: 0.5547 - val_footwear_output_loss: 0.6015 - val_pose_output_loss: 0.5488 - val_emotion_output_loss: 0.4019 - val_gender_output_acc: 0.5610 - val_image_quality_output_acc: 0.7147 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8241 - val_bag_output_acc: 0.7102 - val_footwear_output_acc: 0.6695 - val_pose_output_acc: 0.7453 - val_emotion_output_acc: 0.8490\n",
            "Epoch 2/10\n",
            "360/360 [==============================] - 96s 266ms/step - loss: 4.2946 - gender_output_loss: 0.6860 - image_quality_output_loss: 0.5882 - age_output_loss: 0.4689 - weight_output_loss: 0.4352 - bag_output_loss: 0.5578 - footwear_output_loss: 0.6015 - pose_output_loss: 0.5556 - emotion_output_loss: 0.4014 - gender_output_acc: 0.5535 - image_quality_output_acc: 0.6915 - age_output_acc: 0.7982 - weight_output_acc: 0.8162 - bag_output_acc: 0.7027 - footwear_output_acc: 0.6720 - pose_output_acc: 0.7424 - emotion_output_acc: 0.8568 - val_loss: 4.2653 - val_gender_output_loss: 0.6932 - val_image_quality_output_loss: 0.5846 - val_age_output_loss: 0.4678 - val_weight_output_loss: 0.4278 - val_bag_output_loss: 0.5566 - val_footwear_output_loss: 0.5716 - val_pose_output_loss: 0.5632 - val_emotion_output_loss: 0.4005 - val_gender_output_acc: 0.5244 - val_image_quality_output_acc: 0.7117 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8241 - val_bag_output_acc: 0.7097 - val_footwear_output_acc: 0.7063 - val_pose_output_acc: 0.7453 - val_emotion_output_acc: 0.8490\n",
            "Epoch 3/10\n",
            "360/360 [==============================] - 96s 266ms/step - loss: 4.2662 - gender_output_loss: 0.6850 - image_quality_output_loss: 0.5863 - age_output_loss: 0.4669 - weight_output_loss: 0.4320 - bag_output_loss: 0.5578 - footwear_output_loss: 0.5871 - pose_output_loss: 0.5531 - emotion_output_loss: 0.3980 - gender_output_acc: 0.5551 - image_quality_output_acc: 0.6934 - age_output_acc: 0.7995 - weight_output_acc: 0.8162 - bag_output_acc: 0.7028 - footwear_output_acc: 0.6845 - pose_output_acc: 0.7441 - emotion_output_acc: 0.8570 - val_loss: 4.2618 - val_gender_output_loss: 0.6835 - val_image_quality_output_loss: 0.5909 - val_age_output_loss: 0.4676 - val_weight_output_loss: 0.4211 - val_bag_output_loss: 0.5538 - val_footwear_output_loss: 0.5869 - val_pose_output_loss: 0.5536 - val_emotion_output_loss: 0.4043 - val_gender_output_acc: 0.5587 - val_image_quality_output_acc: 0.6690 - val_age_output_acc: 0.7749 - val_weight_output_acc: 0.8240 - val_bag_output_acc: 0.7107 - val_footwear_output_acc: 0.6932 - val_pose_output_acc: 0.7453 - val_emotion_output_acc: 0.8490\n",
            "Epoch 4/10\n",
            "360/360 [==============================] - 95s 265ms/step - loss: 4.2637 - gender_output_loss: 0.6868 - image_quality_output_loss: 0.5873 - age_output_loss: 0.4679 - weight_output_loss: 0.4310 - bag_output_loss: 0.5587 - footwear_output_loss: 0.5826 - pose_output_loss: 0.5537 - emotion_output_loss: 0.3959 - gender_output_acc: 0.5514 - image_quality_output_acc: 0.6924 - age_output_acc: 0.7988 - weight_output_acc: 0.8165 - bag_output_acc: 0.7022 - footwear_output_acc: 0.6887 - pose_output_acc: 0.7444 - emotion_output_acc: 0.8568 - val_loss: 4.2535 - val_gender_output_loss: 0.6861 - val_image_quality_output_loss: 0.5713 - val_age_output_loss: 0.4680 - val_weight_output_loss: 0.4339 - val_bag_output_loss: 0.5654 - val_footwear_output_loss: 0.5678 - val_pose_output_loss: 0.5487 - val_emotion_output_loss: 0.4125 - val_gender_output_acc: 0.5610 - val_image_quality_output_acc: 0.7060 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8241 - val_bag_output_acc: 0.7109 - val_footwear_output_acc: 0.7177 - val_pose_output_acc: 0.7453 - val_emotion_output_acc: 0.8490\n",
            "Epoch 5/10\n",
            "360/360 [==============================] - 96s 266ms/step - loss: 4.2609 - gender_output_loss: 0.6864 - image_quality_output_loss: 0.5860 - age_output_loss: 0.4677 - weight_output_loss: 0.4329 - bag_output_loss: 0.5563 - footwear_output_loss: 0.5822 - pose_output_loss: 0.5527 - emotion_output_loss: 0.3966 - gender_output_acc: 0.5503 - image_quality_output_acc: 0.6952 - age_output_acc: 0.7988 - weight_output_acc: 0.8167 - bag_output_acc: 0.7045 - footwear_output_acc: 0.6909 - pose_output_acc: 0.7443 - emotion_output_acc: 0.8571 - val_loss: 4.2511 - val_gender_output_loss: 0.6826 - val_image_quality_output_loss: 0.5712 - val_age_output_loss: 0.4758 - val_weight_output_loss: 0.4323 - val_bag_output_loss: 0.5659 - val_footwear_output_loss: 0.5614 - val_pose_output_loss: 0.5477 - val_emotion_output_loss: 0.4141 - val_gender_output_acc: 0.5610 - val_image_quality_output_acc: 0.7135 - val_age_output_acc: 0.7996 - val_weight_output_acc: 0.8241 - val_bag_output_acc: 0.6868 - val_footwear_output_acc: 0.7223 - val_pose_output_acc: 0.7453 - val_emotion_output_acc: 0.8490\n",
            "Epoch 6/10\n",
            "360/360 [==============================] - 96s 267ms/step - loss: 4.2334 - gender_output_loss: 0.6825 - image_quality_output_loss: 0.5857 - age_output_loss: 0.4652 - weight_output_loss: 0.4298 - bag_output_loss: 0.5561 - footwear_output_loss: 0.5707 - pose_output_loss: 0.5499 - emotion_output_loss: 0.3935 - gender_output_acc: 0.5572 - image_quality_output_acc: 0.6935 - age_output_acc: 0.7991 - weight_output_acc: 0.8163 - bag_output_acc: 0.7023 - footwear_output_acc: 0.7018 - pose_output_acc: 0.7445 - emotion_output_acc: 0.8570 - val_loss: 4.2275 - val_gender_output_loss: 0.6813 - val_image_quality_output_loss: 0.5759 - val_age_output_loss: 0.4624 - val_weight_output_loss: 0.4270 - val_bag_output_loss: 0.5573 - val_footwear_output_loss: 0.5724 - val_pose_output_loss: 0.5471 - val_emotion_output_loss: 0.4039 - val_gender_output_acc: 0.5469 - val_image_quality_output_acc: 0.7130 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8241 - val_bag_output_acc: 0.6971 - val_footwear_output_acc: 0.7129 - val_pose_output_acc: 0.7453 - val_emotion_output_acc: 0.8490\n",
            "Epoch 7/10\n",
            "359/360 [============================>.] - ETA: 0s - loss: 4.2376 - gender_output_loss: 0.6809 - image_quality_output_loss: 0.5864 - age_output_loss: 0.4677 - weight_output_loss: 0.4308 - bag_output_loss: 0.5561 - footwear_output_loss: 0.5681 - pose_output_loss: 0.5522 - emotion_output_loss: 0.3956 - gender_output_acc: 0.5545 - image_quality_output_acc: 0.6937 - age_output_acc: 0.7992 - weight_output_acc: 0.8167 - bag_output_acc: 0.7029 - footwear_output_acc: 0.7034 - pose_output_acc: 0.7443 - emotion_output_acc: 0.8571Epoch 7/10\n",
            "360/360 [==============================] - 96s 266ms/step - loss: 4.2374 - gender_output_loss: 0.6808 - image_quality_output_loss: 0.5864 - age_output_loss: 0.4677 - weight_output_loss: 0.4306 - bag_output_loss: 0.5561 - footwear_output_loss: 0.5680 - pose_output_loss: 0.5524 - emotion_output_loss: 0.3955 - gender_output_acc: 0.5549 - image_quality_output_acc: 0.6937 - age_output_acc: 0.7992 - weight_output_acc: 0.8168 - bag_output_acc: 0.7029 - footwear_output_acc: 0.7035 - pose_output_acc: 0.7441 - emotion_output_acc: 0.8571 - val_loss: 4.2252 - val_gender_output_loss: 0.6795 - val_image_quality_output_loss: 0.5750 - val_age_output_loss: 0.4663 - val_weight_output_loss: 0.4330 - val_bag_output_loss: 0.5580 - val_footwear_output_loss: 0.5540 - val_pose_output_loss: 0.5499 - val_emotion_output_loss: 0.4094 - val_gender_output_acc: 0.5665 - val_image_quality_output_acc: 0.7105 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8236 - val_bag_output_acc: 0.7030 - val_footwear_output_acc: 0.7218 - val_pose_output_acc: 0.7453 - val_emotion_output_acc: 0.8490\n",
            "Epoch 8/10\n",
            "360/360 [==============================] - 96s 266ms/step - loss: 4.2079 - gender_output_loss: 0.6742 - image_quality_output_loss: 0.5865 - age_output_loss: 0.4652 - weight_output_loss: 0.4293 - bag_output_loss: 0.5544 - footwear_output_loss: 0.5575 - pose_output_loss: 0.5484 - emotion_output_loss: 0.3924 - gender_output_acc: 0.5645 - image_quality_output_acc: 0.6940 - age_output_acc: 0.7985 - weight_output_acc: 0.8168 - bag_output_acc: 0.7045 - footwear_output_acc: 0.7157 - pose_output_acc: 0.7446 - emotion_output_acc: 0.8570 - val_loss: 4.2161 - val_gender_output_loss: 0.6797 - val_image_quality_output_loss: 0.5740 - val_age_output_loss: 0.4686 - val_weight_output_loss: 0.4265 - val_bag_output_loss: 0.5504 - val_footwear_output_loss: 0.5541 - val_pose_output_loss: 0.5516 - val_emotion_output_loss: 0.4113 - val_gender_output_acc: 0.5615 - val_image_quality_output_acc: 0.7132 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8238 - val_bag_output_acc: 0.7107 - val_footwear_output_acc: 0.7228 - val_pose_output_acc: 0.7453 - val_emotion_output_acc: 0.8490\n",
            "Epoch 9/10\n",
            "360/360 [==============================] - 96s 266ms/step - loss: 4.2079 - gender_output_loss: 0.6742 - image_quality_output_loss: 0.5865 - age_output_loss: 0.4652 - weight_output_loss: 0.4293 - bag_output_loss: 0.5544 - footwear_output_loss: 0.5575 - pose_output_loss: 0.5484 - emotion_output_loss: 0.3924 - gender_output_acc: 0.5645 - image_quality_output_acc: 0.6940 - age_output_acc: 0.7985 - weight_output_acc: 0.8168 - bag_output_acc: 0.7045 - footwear_output_acc: 0.7157 - pose_output_acc: 0.7446 - emotion_output_acc: 0.8570 - val_loss: 4.2161 - val_gender_output_loss: 0.6797 - val_image_quality_output_loss: 0.5740 - val_age_output_loss: 0.4686 - val_weight_output_loss: 0.4265 - val_bag_output_loss: 0.5504 - val_footwear_output_loss: 0.5541 - val_pose_output_loss: 0.5516 - val_emotion_output_loss: 0.4113 - val_gender_output_acc: 0.5615 - val_image_quality_output_acc: 0.7132 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8238 - val_bag_output_acc: 0.7107 - val_footwear_output_acc: 0.7228 - val_pose_output_acc: 0.7453 - val_emotion_output_acc: 0.8490\n",
            "360/360 [==============================] - 96s 266ms/step - loss: 4.1961 - gender_output_loss: 0.6660 - image_quality_output_loss: 0.5867 - age_output_loss: 0.4652 - weight_output_loss: 0.4290 - bag_output_loss: 0.5531 - footwear_output_loss: 0.5522 - pose_output_loss: 0.5497 - emotion_output_loss: 0.3942 - gender_output_acc: 0.5709 - image_quality_output_acc: 0.6931 - age_output_acc: 0.7979 - weight_output_acc: 0.8166 - bag_output_acc: 0.7053 - footwear_output_acc: 0.7161 - pose_output_acc: 0.7447 - emotion_output_acc: 0.8568 - val_loss: 4.2354 - val_gender_output_loss: 0.6732 - val_image_quality_output_loss: 0.5736 - val_age_output_loss: 0.4725 - val_weight_output_loss: 0.4382 - val_bag_output_loss: 0.5634 - val_footwear_output_loss: 0.5509 - val_pose_output_loss: 0.5627 - val_emotion_output_loss: 0.4009 - val_gender_output_acc: 0.5776 - val_image_quality_output_acc: 0.7130 - val_age_output_acc: 0.8000 - val_weight_output_acc: 0.8233 - val_bag_output_acc: 0.6892 - val_footwear_output_acc: 0.7196 - val_pose_output_acc: 0.7456 - val_emotion_output_acc: 0.8490\n",
            "Epoch 10/10\n",
            "360/360 [==============================] - 95s 265ms/step - loss: 4.1825 - gender_output_loss: 0.6640 - image_quality_output_loss: 0.5844 - age_output_loss: 0.4642 - weight_output_loss: 0.4289 - bag_output_loss: 0.5520 - footwear_output_loss: 0.5496 - pose_output_loss: 0.5477 - emotion_output_loss: 0.3918 - gender_output_acc: 0.5766 - image_quality_output_acc: 0.6955 - age_output_acc: 0.7989 - weight_output_acc: 0.8166 - bag_output_acc: 0.7066 - footwear_output_acc: 0.7219 - pose_output_acc: 0.7442 - emotion_output_acc: 0.8568 - val_loss: 4.2308 - val_gender_output_loss: 0.6765 - val_image_quality_output_loss: 0.5776 - val_age_output_loss: 0.4682 - val_weight_output_loss: 0.4357 - val_bag_output_loss: 0.5538 - val_footwear_output_loss: 0.5582 - val_pose_output_loss: 0.5507 - val_emotion_output_loss: 0.4101 - val_gender_output_acc: 0.5678 - val_image_quality_output_acc: 0.7127 - val_age_output_acc: 0.7900 - val_weight_output_acc: 0.8241 - val_bag_output_acc: 0.7112 - val_footwear_output_acc: 0.7132 - val_pose_output_acc: 0.7453 - val_emotion_output_acc: 0.8490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Tb-mWEeHXts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyprJE1mGuda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot(history):\n",
        "  # summarize history for accuracy\n",
        "  \n",
        "  for k in history.history.keys():\n",
        "    plt.plot(history.history[k])\n",
        "  plt.title('model')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLgohe8rSRj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss_and_acc(history):\n",
        "  # plt.plot(history.history['loss'])\n",
        "  # plt.plot(history.history['val_loss'])\n",
        "  plt.plot(history.history['val_gender_output_acc'])\n",
        "  plt.plot(history.history['val_image_quality_output_acc'])\n",
        "  plt.plot(history.history['val_age_output_acc'])\n",
        "  plt.plot(history.history['val_weight_output_acc'])\n",
        "  plt.plot(history.history['val_bag_output_acc'])\n",
        "  plt.plot(history.history['val_footwear_output_acc'])\n",
        "  plt.plot(history.history['val_pose_output_acc'])\n",
        "  plt.plot(history.history['val_emotion_output_acc'])\n",
        "  \n",
        "  plt.legend(['val_gender_output_acc', \n",
        "              'val_image_quality_output_acc', \n",
        "              'val_age_output_acc', \n",
        "              'val_weight_output_acc', \n",
        "              'val_bag_output_acc', \n",
        "              'val_footwear_output_acc', \n",
        "              'val_pose_output_acc', \n",
        "              'val_emotion_output_acc'], loc='upper left')\n",
        "  plt.savefig('vgg16-untrained-10epochs.jpg')\n",
        "  plt.show()\n",
        "  files.download('vgg16-untrained-10epochs.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AGn1ZqyR9Ho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c30742a5-2c14-4aa3-e427-ba9a4a44a510"
      },
      "source": [
        "from google.colab import files\n",
        "plot_loss_and_acc(history)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9Eop5eQ00SullJPTRK+UUk7u/wAPlEhI8PYGfgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI1hJb4qM6OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}