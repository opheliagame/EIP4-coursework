{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 5 ResNet18.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "outputId": "4464ec08-a410-4e95-97a6-a73bbd0c85d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "replace resized/9733.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/              \u001b[01;34mresized\u001b[0m/      \u001b[01;34msaved_models\u001b[0m/\n",
            "hvc_annotations.csv  \u001b[01;34msample_data\u001b[0m/  vgg16-untrained-10epochs.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNnjYupkLp63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "6d604ccc-dcf6-4f30-f992-b39f8ac7a049"
      },
      "source": [
        "!pip install git+https://github.com/qubvel/classification_models.git"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/qubvel/classification_models.git\n",
            "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-r5jwlr0e\n",
            "  Running command git clone -q https://github.com/qubvel/classification_models.git /tmp/pip-req-build-r5jwlr0e\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied (use --upgrade to upgrade): image-classifiers==1.0.0 from git+https://github.com/qubvel/classification_models.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from image-classifiers==1.0.0) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.17.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (2.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.12.0)\n",
            "Building wheels for collected packages: image-classifiers\n",
            "  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-cp36-none-any.whl size=19950 sha256=b3d49379404f96e15366369b4423df98ec3f3193ce85bae6157186ef1f8947a3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-opb1a4xh/wheels/de/2b/fd/29a6d33edb8c28bc7d94e95ea1d39c9a218ac500a3cfb1b197\n",
            "Successfully built image-classifiers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "from keras.applications import ResNet50\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojp7mZPeegyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "BATCH_SIZE =  32#@param {type:\"integer\"}\n",
        "MOMENTUM = 0.9 #@param {type:\"number\"}\n",
        "LEARNING_RATE = 0.01 #@param {type:\"number\"}\n",
        "WEIGHT_DECAY = 5e-4 #@param {type:\"number\"}\n",
        "EPOCHS =  10#@param {type:\"integer\"}\n",
        "DATA_AUGMENTATION = True #@param {type: \"boolean\"}\n",
        "PIXEL_LEVEL = False #@param {type: \"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "outputId": "617c3591-53bf-4fa8-8d32-3e387e092268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>imagequality</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>carryingbag</th>\n",
              "      <th>footwear</th>\n",
              "      <th>emotion</th>\n",
              "      <th>bodypose</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>over-weight</td>\n",
              "      <td>None</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Angry/Serious</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Daily/Office/Work Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>Good</td>\n",
              "      <td>35-45</td>\n",
              "      <td>slightly-overweight</td>\n",
              "      <td>None</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender imagequality    age  ...        emotion        bodypose     image_path\n",
              "0    male      Average  35-45  ...        Neutral  Front-Frontish  resized/1.jpg\n",
              "1  female      Average  35-45  ...  Angry/Serious  Front-Frontish  resized/2.jpg\n",
              "2    male         Good  45-55  ...        Neutral  Front-Frontish  resized/3.jpg\n",
              "3    male         Good  45-55  ...        Neutral  Front-Frontish  resized/4.jpg\n",
              "4  female         Good  35-45  ...        Neutral  Front-Frontish  resized/5.jpg\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "outputId": "8cf91e04-d854-459c-9a41-374ca46154d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "\n",
        "cols = ['gender', 'imagequality', 'age', 'weight', 'carryingbag', 'footwear', 'emotion', 'bodypose']\n",
        "for c in cols:\n",
        "  merged = [i for i in one_hot_df.columns if i.startswith(c)]\n",
        "  one_hot_df[c] = one_hot_df[merged].values.tolist()\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>image_path</th>\n",
              "      <td>resized/1.jpg</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_female</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_male</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Average</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality_Good</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_15-25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_25-35</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_35-45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_45-55</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_55+</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_over-weight</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight_underweight</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag_None</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear_Normal</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Happy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion_Sad</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Back</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose_Side</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>[0, 1]</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[0, 1]</td>\n",
              "      <td>[0, 1]</td>\n",
              "      <td>[1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>imagequality</th>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>[0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight</th>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carryingbag</th>\n",
              "      <td>[0, 1, 0]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>footwear</th>\n",
              "      <td>[0, 0, 1]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bodypose</th>\n",
              "      <td>[0, 1, 0]</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    0  ...                4\n",
              "image_path                              resized/1.jpg  ...    resized/5.jpg\n",
              "gender_female                                       0  ...                1\n",
              "gender_male                                         1  ...                0\n",
              "imagequality_Average                                1  ...                0\n",
              "imagequality_Bad                                    0  ...                0\n",
              "imagequality_Good                                   0  ...                1\n",
              "age_15-25                                           0  ...                0\n",
              "age_25-35                                           0  ...                0\n",
              "age_35-45                                           1  ...                1\n",
              "age_45-55                                           0  ...                0\n",
              "age_55+                                             0  ...                0\n",
              "weight_normal-healthy                               1  ...                0\n",
              "weight_over-weight                                  0  ...                0\n",
              "weight_slightly-overweight                          0  ...                1\n",
              "weight_underweight                                  0  ...                0\n",
              "carryingbag_Daily/Office/Work Bag                   0  ...                0\n",
              "carryingbag_Grocery/Home/Plastic Bag                1  ...                0\n",
              "carryingbag_None                                    0  ...                1\n",
              "footwear_CantSee                                    0  ...                1\n",
              "footwear_Fancy                                      0  ...                0\n",
              "footwear_Normal                                     1  ...                0\n",
              "emotion_Angry/Serious                               0  ...                0\n",
              "emotion_Happy                                       0  ...                0\n",
              "emotion_Neutral                                     1  ...                1\n",
              "emotion_Sad                                         0  ...                0\n",
              "bodypose_Back                                       0  ...                0\n",
              "bodypose_Front-Frontish                             1  ...                1\n",
              "bodypose_Side                                       0  ...                0\n",
              "gender                                         [0, 1]  ...           [1, 0]\n",
              "imagequality                                [1, 0, 0]  ...        [0, 0, 1]\n",
              "age                                   [0, 0, 1, 0, 0]  ...  [0, 0, 1, 0, 0]\n",
              "weight                                   [1, 0, 0, 0]  ...     [0, 0, 1, 0]\n",
              "carryingbag                                 [0, 1, 0]  ...        [0, 0, 1]\n",
              "footwear                                    [0, 0, 1]  ...        [1, 0, 0]\n",
              "emotion                                  [0, 0, 1, 0]  ...     [0, 0, 1, 0]\n",
              "bodypose                                    [0, 1, 0]  ...        [0, 1, 0]\n",
              "\n",
              "[36 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "outputId": "efcc3389-147f-4dc5-fad9-021e318b9e7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11537, 36), (2036, 36))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "outputId": "5c01b11c-f30e-426c-9f46-3b28eb8ef3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>gender_female</th>\n",
              "      <th>gender_male</th>\n",
              "      <th>imagequality_Average</th>\n",
              "      <th>imagequality_Bad</th>\n",
              "      <th>imagequality_Good</th>\n",
              "      <th>age_15-25</th>\n",
              "      <th>age_25-35</th>\n",
              "      <th>age_35-45</th>\n",
              "      <th>age_45-55</th>\n",
              "      <th>age_55+</th>\n",
              "      <th>weight_normal-healthy</th>\n",
              "      <th>weight_over-weight</th>\n",
              "      <th>weight_slightly-overweight</th>\n",
              "      <th>weight_underweight</th>\n",
              "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
              "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
              "      <th>carryingbag_None</th>\n",
              "      <th>footwear_CantSee</th>\n",
              "      <th>footwear_Fancy</th>\n",
              "      <th>footwear_Normal</th>\n",
              "      <th>emotion_Angry/Serious</th>\n",
              "      <th>emotion_Happy</th>\n",
              "      <th>emotion_Neutral</th>\n",
              "      <th>emotion_Sad</th>\n",
              "      <th>bodypose_Back</th>\n",
              "      <th>bodypose_Front-Frontish</th>\n",
              "      <th>bodypose_Side</th>\n",
              "      <th>gender</th>\n",
              "      <th>imagequality</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>carryingbag</th>\n",
              "      <th>footwear</th>\n",
              "      <th>emotion</th>\n",
              "      <th>bodypose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4740</th>\n",
              "      <td>resized/4741.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13525</th>\n",
              "      <td>resized/13527.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5580</th>\n",
              "      <td>resized/5581.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>resized/5109.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4815</th>\n",
              "      <td>resized/4816.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 1]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              image_path  gender_female  ...       emotion   bodypose\n",
              "4740    resized/4741.jpg              1  ...  [0, 0, 1, 0]  [0, 1, 0]\n",
              "13525  resized/13527.jpg              1  ...  [0, 0, 1, 0]  [0, 0, 1]\n",
              "5580    resized/5581.jpg              1  ...  [0, 0, 1, 0]  [1, 0, 0]\n",
              "5108    resized/5109.jpg              1  ...  [0, 0, 1, 0]  [1, 0, 0]\n",
              "4815    resized/4816.jpg              0  ...  [0, 0, 0, 1]  [0, 1, 0]\n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_gen = PersonDataGenerator(train_df, batch_size=BATCH_SIZE)\n",
        "valid_gen = PersonDataGenerator(val_df, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "outputId": "a7391617-7f55-4e44-b4c1-e7c44973f875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "print(images.shape)\n",
        "print(targets.keys())\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1]-1 for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 224, 224, 3)\n",
            "dict_keys(['gender_output', 'image_quality_output', 'age_output', 'weight_output', 'bag_output', 'pose_output', 'footwear_output', 'emotion_output'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 5,\n",
              " 'bag': 3,\n",
              " 'emotion': 4,\n",
              " 'footwear': 3,\n",
              " 'gender': 2,\n",
              " 'image_quality': 3,\n",
              " 'pose': 3,\n",
              " 'weight': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G3_2YTReYyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 5:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 10:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 15:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 20:\n",
        "        lr *= 1e-1\n",
        "    #lr = round(0.004 * 1/(1 + 0.319 * epoch), 10)\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnXEYMdDdUaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynTC3bYOvN7C",
        "colab_type": "code",
        "outputId": "1091bd90-1b1e-41ae-cbf8-61a26c1a6b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from classification_models.keras import Classifiers\n",
        "\n",
        "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "\n",
        "backbone = ResNet18(\n",
        "    weights=None, \n",
        "    include_top=False, \n",
        "    input_tensor=Input(shape=(256, 256, 3))\n",
        ")\n",
        "\n",
        "neck = backbone.output\n",
        "neck = Flatten(name=\"flatten\")(neck)\n",
        "neck = Dense(512, activation=\"relu\")(neck)\n",
        "\n",
        "\n",
        "def build_tower(in_layer):\n",
        "    neck = Dropout(0.2)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    neck = Dropout(0.3)(in_layer)\n",
        "    neck = Dense(128, activation=\"relu\")(neck)\n",
        "    return neck\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "\n",
        "# heads\n",
        "gender = build_head(\"gender\", build_tower(neck))\n",
        "image_quality = build_head(\"image_quality\", build_tower(neck))\n",
        "age = build_head(\"age\", build_tower(neck))\n",
        "weight = build_head(\"weight\", build_tower(neck))\n",
        "bag = build_head(\"bag\", build_tower(neck))\n",
        "footwear = build_head(\"footwear\", build_tower(neck))\n",
        "emotion = build_head(\"emotion\", build_tower(neck))\n",
        "pose = build_head(\"pose\", build_tower(neck))\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    inputs=backbone.input, \n",
        "    outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_19 (ZeroPadding2 (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d_19[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_20 (ZeroPadding2 (None, 130, 130, 64) 0           relu0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_20[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_21 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_21[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_22 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_22[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_sc (Conv2D)        (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 64, 64, 64)   0           stage1_unit1_conv2[0][0]         \n",
            "                                                                 stage1_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_23 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_23[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_24 (ZeroPadding2 (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_24[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 64, 64, 64)   0           stage1_unit2_conv2[0][0]         \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage2_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_25 (ZeroPadding2 (None, 66, 66, 64)   0           stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv1 (Conv2D)     (None, 32, 32, 128)  73728       zero_padding2d_25[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_26 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_26[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_sc (Conv2D)        (None, 32, 32, 128)  8192        stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 32, 32, 128)  0           stage2_unit1_conv2[0][0]         \n",
            "                                                                 stage2_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu1 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_27 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_27[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_28 (ZeroPadding2 (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_28[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 32, 32, 128)  0           stage2_unit2_conv2[0][0]         \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 128)  512         add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu1 (Activation) (None, 32, 32, 128)  0           stage3_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_29 (ZeroPadding2 (None, 34, 34, 128)  0           stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv1 (Conv2D)     (None, 16, 16, 256)  294912      zero_padding2d_29[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_30 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_30[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_sc (Conv2D)        (None, 16, 16, 256)  32768       stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 16, 16, 256)  0           stage3_unit1_conv2[0][0]         \n",
            "                                                                 stage3_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu1 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_31 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_31[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_32 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_32[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 16, 16, 256)  0           stage3_unit2_conv2[0][0]         \n",
            "                                                                 add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 256)  1024        add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu1 (Activation) (None, 16, 16, 256)  0           stage4_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_33 (ZeroPadding2 (None, 18, 18, 256)  0           stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv1 (Conv2D)     (None, 8, 8, 512)    1179648     zero_padding2d_33[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_34 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_34[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_sc (Conv2D)        (None, 8, 8, 512)    131072      stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 8, 8, 512)    0           stage4_unit1_conv2[0][0]         \n",
            "                                                                 stage4_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 512)    2048        add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu1 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_35 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_35[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_36 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_36[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 512)    0           stage4_unit2_conv2[0][0]         \n",
            "                                                                 add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn1 (BatchNormalization)        (None, 8, 8, 512)    2048        add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu1 (Activation)              (None, 8, 8, 512)    0           bn1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 32768)        0           relu1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 512)          16777728    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 512)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 512)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 512)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 512)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 512)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 512)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 512)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 512)          0           dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 128)          65664       dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 128)          65664       dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 128)          65664       dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 128)          65664       dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 128)          65664       dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 128)          65664       dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_34 (Dense)                (None, 128)          65664       dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 128)          65664       dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Dense)           (None, 2)            258         dense_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "image_quality_output (Dense)    (None, 3)            387         dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "age_output (Dense)              (None, 5)            645         dense_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "weight_output (Dense)           (None, 4)            516         dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bag_output (Dense)              (None, 3)            387         dense_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "footwear_output (Dense)         (None, 3)            387         dense_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pose_output (Dense)             (None, 3)            387         dense_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "emotion_output (Dense)          (None, 4)            516         dense_32[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 28,493,412\n",
            "Trainable params: 28,485,470\n",
            "Non-trainable params: 7,942\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfPG9C2eA1zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = {\n",
        "\t\"gender_output\": \"binary_crossentropy\",\n",
        "\t\"image_quality_output\": \"categorical_crossentropy\",\n",
        "\t\"age_output\": \"categorical_crossentropy\",\n",
        "\t\"weight_output\": \"categorical_crossentropy\",\n",
        "  \"bag_output\": \"categorical_crossentropy\",\n",
        "  \"footwear_output\": \"categorical_crossentropy\",\n",
        "  \"pose_output\": \"categorical_crossentropy\",\n",
        "  \"emotion_output\": \"categorical_crossentropy\"\n",
        "}\n",
        "loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \n",
        "                \"age_output\": 1.0, \"weight_output\": 1.0, \n",
        "                \"bag_output\": 1.0, \"footwear_output\": 1.0, \n",
        "                \"pose_output\": 1.0, \"emotion_output\": 1.0}\n",
        "sgd = SGD(lr=LEARNING_RATE, momentum=MOMENTUM, nesterov=True) \n",
        "model.compile(\n",
        "    optimizer=sgd,\n",
        "    loss=losses, \n",
        "    loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw2ZRIQ7BW-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "9acdc94a-3e18-4eea-9596-856f9f66e6e7"
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = '%s_model.{epoch:03d}.h5' % 'resnet50'\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "callbacks = [checkpoint, lr_scheduler]\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not DATA_AUGMENTATION:\n",
        "    print('Not using data augmentation.')\n",
        "    history = model.fit_generator(\n",
        "              generator=train_gen,\n",
        "              validation_data=valid_gen,\n",
        "              batch_size=32,\n",
        "              epochs=50,\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=PIXEL_LEVEL))\n",
        "    \n",
        "    valid_datagen = ImageDataGenerator(\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "    \n",
        "    train_gen = train_datagen.flow_from_dataframe(\n",
        "                          dataframe=train_df, \n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          x_col='image_path',\n",
        "                          y_col=['gender', 'imagequality', 'age', 'weight', 'carryingbag', 'footwear', 'bodypose', 'emotion'],\n",
        "                          shuffle=True,\n",
        "                          class_mode=\"multi_output\")\n",
        "\n",
        "    valid_gen = valid_datagen.flow_from_dataframe(\n",
        "                          dataframe=val_df,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          x_col='image_path',\n",
        "                          y_col=['gender', 'imagequality', 'age', 'weight', 'carryingbag', 'footwear', 'bodypose', 'emotion'],\n",
        "                          shuffle=True,\n",
        "                          class_mode=\"multi_output\")\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    #datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit_generator(\n",
        "                        generator=train_gen,\n",
        "                        validation_data=valid_gen,\n",
        "                        use_multiprocessing=True,\n",
        "                        epochs=EPOCHS, \n",
        "                        verbose=1, \n",
        "                        workers=20,\n",
        "                        callbacks=callbacks\n",
        "                        )"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Found 11537 validated image filenames.\n",
            "Found 2036 validated image filenames.\n",
            "Epoch 1/10\n",
            "Learning rate:  0.001\n",
            "360/361 [============================>.] - ETA: 0s - loss: 8.0874 - gender_output_loss: 0.6985 - image_quality_output_loss: 1.0035 - age_output_loss: 1.4760 - weight_output_loss: 1.0314 - bag_output_loss: 0.9451 - footwear_output_loss: 1.0252 - pose_output_loss: 0.9565 - emotion_output_loss: 0.9512 - gender_output_acc: 0.5395 - image_quality_output_acc: 0.5444 - age_output_acc: 0.3708 - weight_output_acc: 0.6287 - bag_output_acc: 0.5461 - footwear_output_acc: 0.4905 - pose_output_acc: 0.6087 - emotion_output_acc: 0.7089\n",
            "\n",
            "361/361 [==============================] - 203s 563ms/step - loss: 8.0874 - gender_output_loss: 0.6984 - image_quality_output_loss: 1.0033 - age_output_loss: 1.4758 - weight_output_loss: 1.0316 - bag_output_loss: 0.9453 - footwear_output_loss: 1.0250 - pose_output_loss: 0.9566 - emotion_output_loss: 0.9514 - gender_output_acc: 0.5397 - image_quality_output_acc: 0.5445 - age_output_acc: 0.3708 - weight_output_acc: 0.6286 - bag_output_acc: 0.5462 - footwear_output_acc: 0.4905 - pose_output_acc: 0.6086 - emotion_output_acc: 0.7088 - val_loss: 7.8938 - val_gender_output_loss: 0.6803 - val_image_quality_output_loss: 1.0011 - val_age_output_loss: 1.4377 - val_weight_output_loss: 1.0087 - val_bag_output_loss: 0.9312 - val_footwear_output_loss: 0.9754 - val_pose_output_loss: 0.9324 - val_emotion_output_loss: 0.9270 - val_gender_output_acc: 0.5496 - val_image_quality_output_acc: 0.5339 - val_age_output_acc: 0.4067 - val_weight_output_acc: 0.6243 - val_bag_output_acc: 0.5354 - val_footwear_output_acc: 0.5147 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7068\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/10\n",
            "Learning rate:  0.001\n",
            "361/361 [==============================] - 189s 524ms/step - loss: 7.8679 - gender_output_loss: 0.6726 - image_quality_output_loss: 0.9897 - age_output_loss: 1.4370 - weight_output_loss: 1.0001 - bag_output_loss: 0.9266 - footwear_output_loss: 0.9713 - pose_output_loss: 0.9376 - emotion_output_loss: 0.9329 - gender_output_acc: 0.5631 - image_quality_output_acc: 0.5556 - age_output_acc: 0.3908 - weight_output_acc: 0.6360 - bag_output_acc: 0.5599 - footwear_output_acc: 0.5334 - pose_output_acc: 0.6163 - emotion_output_acc: 0.7129 - val_loss: 7.8305 - val_gender_output_loss: 0.6641 - val_image_quality_output_loss: 1.0010 - val_age_output_loss: 1.4127 - val_weight_output_loss: 1.0026 - val_bag_output_loss: 0.9275 - val_footwear_output_loss: 0.9650 - val_pose_output_loss: 0.9334 - val_emotion_output_loss: 0.9242 - val_gender_output_acc: 0.5663 - val_image_quality_output_acc: 0.5265 - val_age_output_acc: 0.4062 - val_weight_output_acc: 0.6267 - val_bag_output_acc: 0.5476 - val_footwear_output_acc: 0.5349 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7068\n",
            "Epoch 3/10\n",
            "Learning rate:  0.001\n",
            "361/361 [==============================] - 189s 523ms/step - loss: 7.8148 - gender_output_loss: 0.6641 - image_quality_output_loss: 0.9833 - age_output_loss: 1.4337 - weight_output_loss: 0.9949 - bag_output_loss: 0.9221 - footwear_output_loss: 0.9577 - pose_output_loss: 0.9345 - emotion_output_loss: 0.9246 - gender_output_acc: 0.5749 - image_quality_output_acc: 0.5555 - age_output_acc: 0.3951 - weight_output_acc: 0.6366 - bag_output_acc: 0.5601 - footwear_output_acc: 0.5464 - pose_output_acc: 0.6165 - emotion_output_acc: 0.7126 - val_loss: 7.7385 - val_gender_output_loss: 0.6453 - val_image_quality_output_loss: 0.9934 - val_age_output_loss: 1.4089 - val_weight_output_loss: 1.0025 - val_bag_output_loss: 0.9120 - val_footwear_output_loss: 0.9367 - val_pose_output_loss: 0.9222 - val_emotion_output_loss: 0.9175 - val_gender_output_acc: 0.5904 - val_image_quality_output_acc: 0.5339 - val_age_output_acc: 0.4077 - val_weight_output_acc: 0.6272 - val_bag_output_acc: 0.5530 - val_footwear_output_acc: 0.5619 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7068\n",
            "Epoch 4/10\n",
            "Learning rate:  0.001\n",
            "360/361 [============================>.] - ETA: 0s - loss: 7.7642 - gender_output_loss: 0.6580 - image_quality_output_loss: 0.9794 - age_output_loss: 1.4254 - weight_output_loss: 0.9914 - bag_output_loss: 0.9156 - footwear_output_loss: 0.9443 - pose_output_loss: 0.9311 - emotion_output_loss: 0.9189 - gender_output_acc: 0.5918 - image_quality_output_acc: 0.5551 - age_output_acc: 0.3920 - weight_output_acc: 0.6377 - bag_output_acc: 0.5621 - footwear_output_acc: 0.5555 - pose_output_acc: 0.6168 - emotion_output_acc: 0.7126Epoch 4/10 0.001\n",
            "361/361 [==============================] - 189s 523ms/step - loss: 7.7648 - gender_output_loss: 0.6580 - image_quality_output_loss: 0.9797 - age_output_loss: 1.4251 - weight_output_loss: 0.9915 - bag_output_loss: 0.9157 - footwear_output_loss: 0.9445 - pose_output_loss: 0.9312 - emotion_output_loss: 0.9191 - gender_output_acc: 0.5916 - image_quality_output_acc: 0.5549 - age_output_acc: 0.3922 - weight_output_acc: 0.6376 - bag_output_acc: 0.5618 - footwear_output_acc: 0.5553 - pose_output_acc: 0.6166 - emotion_output_acc: 0.7124 - val_loss: 7.7216 - val_gender_output_loss: 0.6498 - val_image_quality_output_loss: 0.9885 - val_age_output_loss: 1.4045 - val_weight_output_loss: 1.0080 - val_bag_output_loss: 0.9106 - val_footwear_output_loss: 0.9172 - val_pose_output_loss: 0.9169 - val_emotion_output_loss: 0.9260 - val_gender_output_acc: 0.6125 - val_image_quality_output_acc: 0.5339 - val_age_output_acc: 0.3959 - val_weight_output_acc: 0.6272 - val_bag_output_acc: 0.5530 - val_footwear_output_acc: 0.5825 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7068\n",
            "Epoch 5/10\n",
            "Learning rate:  0.001\n",
            "361/361 [==============================] - 187s 519ms/step - loss: 7.7389 - gender_output_loss: 0.6507 - image_quality_output_loss: 0.9789 - age_output_loss: 1.4240 - weight_output_loss: 0.9906 - bag_output_loss: 0.9131 - footwear_output_loss: 0.9383 - pose_output_loss: 0.9262 - emotion_output_loss: 0.9172 - gender_output_acc: 0.5964 - image_quality_output_acc: 0.5555 - age_output_acc: 0.3979 - weight_output_acc: 0.6365 - bag_output_acc: 0.5615 - footwear_output_acc: 0.5609 - pose_output_acc: 0.6165 - emotion_output_acc: 0.7124 - val_loss: 7.7118 - val_gender_output_loss: 0.6356 - val_image_quality_output_loss: 0.9876 - val_age_output_loss: 1.4164 - val_weight_output_loss: 0.9993 - val_bag_output_loss: 0.9120 - val_footwear_output_loss: 0.9262 - val_pose_output_loss: 0.9160 - val_emotion_output_loss: 0.9187 - val_gender_output_acc: 0.6498 - val_image_quality_output_acc: 0.5295 - val_age_output_acc: 0.4003 - val_weight_output_acc: 0.6272 - val_bag_output_acc: 0.5530 - val_footwear_output_acc: 0.5855 - val_pose_output_acc: 0.6238 - val_emotion_output_acc: 0.7068\n",
            "Epoch 6/10\n",
            "Learning rate:  0.001\n",
            "Learning rate:  0.001\n",
            "361/361 [==============================] - 188s 522ms/step - loss: 7.6990 - gender_output_loss: 0.6447 - image_quality_output_loss: 0.9793 - age_output_loss: 1.4212 - weight_output_loss: 0.9852 - bag_output_loss: 0.9088 - footwear_output_loss: 0.9217 - pose_output_loss: 0.9241 - emotion_output_loss: 0.9139 - gender_output_acc: 0.6006 - image_quality_output_acc: 0.5558 - age_output_acc: 0.3938 - weight_output_acc: 0.6371 - bag_output_acc: 0.5613 - footwear_output_acc: 0.5758 - pose_output_acc: 0.6161 - emotion_output_acc: 0.7123 - val_loss: 7.6457 - val_gender_output_loss: 0.6223 - val_image_quality_output_loss: 0.9810 - val_age_output_loss: 1.4106 - val_weight_output_loss: 0.9992 - val_bag_output_loss: 0.9059 - val_footwear_output_loss: 0.8824 - val_pose_output_loss: 0.9033 - val_emotion_output_loss: 0.9410 - val_gender_output_acc: 0.6277 - val_image_quality_output_acc: 0.5349 - val_age_output_acc: 0.4042 - val_weight_output_acc: 0.6272 - val_bag_output_acc: 0.5530 - val_footwear_output_acc: 0.5982 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7068\n",
            "Epoch 7/10\n",
            "Learning rate:  5e-07\n",
            "361/361 [==============================] - 187s 519ms/step - loss: 7.7469 - gender_output_loss: 0.6448 - image_quality_output_loss: 0.9829 - age_output_loss: 1.4229 - weight_output_loss: 0.9959 - bag_output_loss: 0.9149 - footwear_output_loss: 0.9361 - pose_output_loss: 0.9291 - emotion_output_loss: 0.9203 - gender_output_acc: 0.6043 - image_quality_output_acc: 0.5564 - age_output_acc: 0.3899 - weight_output_acc: 0.6342 - bag_output_acc: 0.5650 - footwear_output_acc: 0.5642 - pose_output_acc: 0.6163 - emotion_output_acc: 0.7113 - val_loss: 7.6486 - val_gender_output_loss: 0.6232 - val_image_quality_output_loss: 0.9872 - val_age_output_loss: 1.4132 - val_weight_output_loss: 1.0034 - val_bag_output_loss: 0.9035 - val_footwear_output_loss: 0.8786 - val_pose_output_loss: 0.8998 - val_emotion_output_loss: 0.9397 - val_gender_output_acc: 0.6341 - val_image_quality_output_acc: 0.5383 - val_age_output_acc: 0.3954 - val_weight_output_acc: 0.6238 - val_bag_output_acc: 0.5530 - val_footwear_output_acc: 0.6031 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7058\n",
            "Epoch 8/10\n",
            "Learning rate:  5e-07\n",
            "361/361 [==============================] - 185s 513ms/step - loss: 7.7339 - gender_output_loss: 0.6445 - image_quality_output_loss: 0.9824 - age_output_loss: 1.4206 - weight_output_loss: 0.9929 - bag_output_loss: 0.9159 - footwear_output_loss: 0.9260 - pose_output_loss: 0.9320 - emotion_output_loss: 0.9197 - gender_output_acc: 0.6143 - image_quality_output_acc: 0.5572 - age_output_acc: 0.3870 - weight_output_acc: 0.6334 - bag_output_acc: 0.5656 - footwear_output_acc: 0.5691 - pose_output_acc: 0.6165 - emotion_output_acc: 0.7112 - val_loss: 7.6434 - val_gender_output_loss: 0.6233 - val_image_quality_output_loss: 0.9837 - val_age_output_loss: 1.4113 - val_weight_output_loss: 1.0017 - val_bag_output_loss: 0.9033 - val_footwear_output_loss: 0.8790 - val_pose_output_loss: 0.9009 - val_emotion_output_loss: 0.9404 - val_gender_output_acc: 0.6316 - val_image_quality_output_acc: 0.5368 - val_age_output_acc: 0.4008 - val_weight_output_acc: 0.6243 - val_bag_output_acc: 0.5530 - val_footwear_output_acc: 0.5977 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7063\n",
            "Epoch 9/10\n",
            "Learning rate:  5e-07\n",
            "361/361 [==============================] - 183s 508ms/step - loss: 7.7256 - gender_output_loss: 0.6460 - image_quality_output_loss: 0.9817 - age_output_loss: 1.4202 - weight_output_loss: 0.9921 - bag_output_loss: 0.9145 - footwear_output_loss: 0.9267 - pose_output_loss: 0.9260 - emotion_output_loss: 0.9183 - gender_output_acc: 0.6102 - image_quality_output_acc: 0.5575 - age_output_acc: 0.3887 - weight_output_acc: 0.6342 - bag_output_acc: 0.5652 - footwear_output_acc: 0.5641 - pose_output_acc: 0.6163 - emotion_output_acc: 0.7118 - val_loss: 7.6370 - val_gender_output_loss: 0.6201 - val_image_quality_output_loss: 0.9841 - val_age_output_loss: 1.4112 - val_weight_output_loss: 1.0020 - val_bag_output_loss: 0.9032 - val_footwear_output_loss: 0.8765 - val_pose_output_loss: 0.9004 - val_emotion_output_loss: 0.9394 - val_gender_output_acc: 0.6390 - val_image_quality_output_acc: 0.5378 - val_age_output_acc: 0.3978 - val_weight_output_acc: 0.6248 - val_bag_output_acc: 0.5530 - val_footwear_output_acc: 0.6031 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7073\n",
            "Epoch 10/10\n",
            "Learning rate:  5e-07\n",
            "Epoch 9/10\n",
            "Learning rate:  5e-07\n",
            "361/361 [==============================] - 185s 514ms/step - loss: 7.7101 - gender_output_loss: 0.6447 - image_quality_output_loss: 0.9799 - age_output_loss: 1.4213 - weight_output_loss: 0.9905 - bag_output_loss: 0.9115 - footwear_output_loss: 0.9187 - pose_output_loss: 0.9255 - emotion_output_loss: 0.9181 - gender_output_acc: 0.6118 - image_quality_output_acc: 0.5563 - age_output_acc: 0.3908 - weight_output_acc: 0.6347 - bag_output_acc: 0.5653 - footwear_output_acc: 0.5763 - pose_output_acc: 0.6166 - emotion_output_acc: 0.7122 - val_loss: 7.6333 - val_gender_output_loss: 0.6194 - val_image_quality_output_loss: 0.9802 - val_age_output_loss: 1.4114 - val_weight_output_loss: 1.0014 - val_bag_output_loss: 0.9034 - val_footwear_output_loss: 0.8767 - val_pose_output_loss: 0.8997 - val_emotion_output_loss: 0.9412 - val_gender_output_acc: 0.6483 - val_image_quality_output_acc: 0.5388 - val_age_output_acc: 0.3998 - val_weight_output_acc: 0.6262 - val_bag_output_acc: 0.5530 - val_footwear_output_acc: 0.5992 - val_pose_output_acc: 0.6243 - val_emotion_output_acc: 0.7068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwP_lR1cemyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "1b20ac86-6c2f-4609-a992-a0977e1db6e4"
      },
      "source": [
        "model.save('resnet18-10epochs.h5')\n",
        "files.download('resnet18-10epochs.h5')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Exception happened during processing of request from ('::ffff:127.0.0.1', 45750, 0, 0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 351, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 364, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 724, in __init__\n",
            "    self.handle()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
            "    self.handle_one_request()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
            "    method()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
            "    self.copyfile(f, self.wfile)\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
            "    shutil.copyfileobj(source, outputfile)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
            "    fdst.write(buf)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 803, in write\n",
            "    self._sock.sendall(b)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "----------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyprJE1mGuda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot(history):\n",
        "  # summarize history for accuracy\n",
        "  \n",
        "  for k in history.history.keys():\n",
        "    plt.plot(history.history[k])\n",
        "  plt.title('model')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLgohe8rSRj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss_and_acc(history):\n",
        "  fig = plt.figure(figsize=(8, 5))\n",
        "  # plt.plot(history.history['loss'])\n",
        "  # plt.plot(history.history['val_loss'])\n",
        "  plt.plot(history.history['val_gender_output_acc'])\n",
        "  plt.plot(history.history['val_image_quality_output_acc'])\n",
        "  plt.plot(history.history['val_age_output_acc'])\n",
        "  plt.plot(history.history['val_weight_output_acc'])\n",
        "  plt.plot(history.history['val_bag_output_acc'])\n",
        "  plt.plot(history.history['val_footwear_output_acc'])\n",
        "  plt.plot(history.history['val_pose_output_acc'])\n",
        "  plt.plot(history.history['val_emotion_output_acc'])\n",
        "  \n",
        "  plt.legend(['val_gender_output_acc', \n",
        "              'val_image_quality_output_acc', \n",
        "              'val_age_output_acc', \n",
        "              'val_weight_output_acc', \n",
        "              'val_bag_output_acc', \n",
        "              'val_footwear_output_acc', \n",
        "              'val_pose_output_acc', \n",
        "              'val_emotion_output_acc'], loc='upper left')\n",
        "  plt.savefig('vgg16-untrained-10epochs.jpg')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AGn1ZqyR9Ho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "4176cf40-6efa-4b7c-8c43-dbb5651efb29"
      },
      "source": [
        "from google.colab import files\n",
        "plot_loss_and_acc(history)\n",
        "files.download('vgg16-untrained-10epochs.jpg')\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEvCAYAAACKSII9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIjlMQS0iIpLDFNQiIiI57P8B2pJrDuW4atEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI1hJb4qM6OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}